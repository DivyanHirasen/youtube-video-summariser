{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-1.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting defusedxml<0.8.0,>=0.7.1 (from youtube-transcript-api)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: requests in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from requests->youtube-transcript-api) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from requests->youtube-transcript-api) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from requests->youtube-transcript-api) (2025.4.26)\n",
      "Downloading youtube_transcript_api-1.1.0-py3-none-any.whl (485 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: defusedxml, youtube-transcript-api\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [youtube-transcript-api]\n",
      "\u001b[1A\u001b[2KSuccessfully installed defusedxml-0.7.1 youtube-transcript-api-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/divyan/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.0/755.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-macosx_11_0_arm64.whl (320 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, pydantic-core, jiter, httpcore, distro, anyio, annotated-types, pydantic, httpx, openai\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [openai]━━\u001b[0m \u001b[32m10/11\u001b[0m [openai]httpx]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.93.0 pydantic-2.11.7 pydantic-core-2.33.2 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n",
    "#openai 1.93.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "#https://www.youtube.com/watch?v=VMGR-v0ZoPs\n",
    "\n",
    "video_id = \"gIEUH5PMrIA\"  # Replace with your video ID\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI decided to change the game on a Friday night. I don't know why they can't wait till Mondays or do this in the middle of the week, but news like this come out over a weekend so everybody can start being extremely bullish for one company and extremely bearish for another company. We can see Google convinces OpenAI to use TPU chips in a win against Nvidia. Well, on today's episode, we're going to take a closer look at OpenAI at Google at Nvidia. Also, Microsoft and Broadcom for those that might not be familiar. that are also kind of impacted in this a little bit. All right, so if you're new here, my name is Jose Naro, and this is going to be the best place you're going to get free information about the AI market, the semiconductor market, and not just about financial numbers, right? You're going to learn about the technology and the overall growth opportunities in all these markets. This is definitely the best place you're going to get any information. So, I don't know what you're doing. It's Friday night. You're here with me. Might as well hit the thumbs up and the subscribe button already. So this is the main topic, right? OpenAI is shifting a little bit to Google to kind of use their TPUs. Now obviously on a very top level overview, this seems like it's a shot against Nvidia, but but I want to give you the other side of the story. If we kind of just look at Samman's history, for the past few months, Samman continues to say that they are out of GPUs. We can see here on February 27th of 202 uh 2025, OpenAI CEO Sim Alman says the company is out of GPUs. Not only that, we also see that uh I I I have another one here. On March 28th of 2025, recent OpenAI launches limited by GPU shortages. So, OpenAI is trying to build as many solutions as they can, but unfortunately they can't because they are shorted in hardware space. And what is OpenAI doing to kind of fix this? It's actually trying to make buddies with a lot of people and raising money to get more and more AI infrastructure. The biggest one was the Stargate project that was announced in I believe in early January if I recall correctly. Yeah, January of 2025th, which is this massive AI investment partnering up with companies like Oracle and SoftBank where OpenAI is building with all those partners massive AI infrastructure that they can use for training and inference. We can also see that um Coreweave uh on March 10th of 2025 announced that they had this massive AI infrastructure deal with OpenAI to expand its overall compute capacity. So why is OpenAI needing all this capacity? First, two things. One, they needed to continue to innovate their own AI technologies. They need to continue to train their next generations of GPT GPT O34 Pro05 and the list goes on and on. The second thing is more people are using AI on a daily basis. So now you have the increased compute demand for more users. And now those more users need way more compute. So you have those two tailwinds increasing the amount of compute capacity that this company needs. And if you want to keep innovating in this space, you can't stand still. you have to stop and you have to go and work with any player that gives you the opportunity to grow more. So, in the past few weeks, we've actually heard this rumor of Sam Alman and OpenAI. It seems like now we're getting even closer to these rumors and these reports being true. So, now I want to say that we can see the market needs more hardware because in its AI chip constraint. So, right now, I don't believe this is bad news for Nvidia. And I'll talk a little bit more about this in in later on through this episode, but I do believe this is extremely extremely bullish for Google. And that's why luckily about 5 days ago, I did a video, Google stock is a steal and Wall Street is wrong. One of my biggest growth opportunities for Google is the cloud market, the cloud infrastructure. And we're going to explain why in a bit. But for those that are are are going to see this episode is going to be filled with a lot of great charts. All these charts you can find at fiscal.ai. It is the data platform that I use on a daily basis for learning about investments, for earnings transcripts, for AI summaries, the list goes on and on. And if you want 15% off and 2 weeks off uh for free, make sure to check out the link below at fiscal.ai/jose. In all honesty, if there is one platform that you need for investing, this is the one. So, make sure to click the link below. That would be a great way to support the platform. And again, I use this on a daily basis. So, now this first chart that I have here is Google Cloud share of total revenue. So, Google has their own infrastructure market, Google Cloud, and this is a market that is continuing to grow its total percentage of revenue. Right now, it's roughly 12.8% of its total revenue. So, it's still very much in the low teens. I personally believe that this is going to grow at rapid levels and this is going to give Google the opportunity to expand its overall valuation expansion because actually, let's pull it up really quick. I'm just going to go here uh to fiscal.ai AI so you can see how quickly and and and this is a chart that I completely forgot to put on but I think it's going to give a great indication of what's happening in this overall space. So here I actually have the Mac 7, I have Nvidia, I have Alphabet, I have Microsoft, I have Apple, I have Amazon and Meta. I'm not adding uh Tesla because Tesla's forward PE ratio is too too crazy. But in a forward PE ratio, Google is the cheapest. Google right now is this one right here. Current 4 PE ratio even after the gains recently is about 19.3. Still below 20. Every other player is in the mid to high 20s or in the low30s. I think eventually when the market wakes up, this is just going to be an easy multiple expansion. And if you continue to grow revenue in a lot of their businesses, this to me is almost a no-brainer. There's never a no-brainer in the market, but this is the closest thing that I can get and one is one of my bullish points. Overall, Google Cloud Share is expected to grow in my opinions. And the main reason is we talked about it in the intro or earlier on in this video. The AI market is kind of constrained with AI chips. But Google has a secret weapon. Google has their TPUs. Their most recent TPU is the Ironwood. And Ironwood is a solution that Google designs and it helps them build AI infrastructure at a faster rate than any other player. So while most other players only can build AI servers with Nvidia chips or AMD chips, Google can do the same. They can go with Nvidia. They could potentially, they haven't done so yet, but they can go with AMD chips. And more importantly, they also build their own chips, which are really, really good. So in theory they have this nice strength in the overall market that we're seeing a lot and a lot of supply constraint in and I think that is a massive massive growth opportunity for Google. Now, uh, the Ironwood is all the other ASIC players, all the other big tech players do have their own ASIC, but from my research, none of them are near enough close to the TPU that Google designs. And here we can go back to fisc.ai. This is Alphabet's latest quarter 1 earnings call. And we can see from the CFO that they stated on the quarter 4 call that we exited the year in cloud specifically with more customer demand than we had capacity and that was the case this quarter as well. So we want to make sure we ramp up to support customer needs and customer demands. So again this is telling us that the AI market is growing so quickly. There's not enough AI servers. The only one that really really has a super strong AS6 solution is Google. So if everybody else is kind of constraint with Nvidia chips, Google is too, but they have that also other Tailwind. I mean, you can also say Amazon has kind of the tranium too, but again in forms of competition TPU, there's none of them close at least from the Max 7 right now. Now to me, this is still a very very strong company. I think Google as we saw valuation is completely underrated and underestimated by analysts and a lot of investors and I am very excited that I did that video just 5 days ago when the stock was in the 160s. I have actually been buying just a few days ago. I actually added an extra 100 shares into my overall portfolio here on Alphabet and I'm going to continue to add whenever I can. Now this is also in my opinion a good case for Broadcom. So Broadcom for those that are not familiar are the helpers of Google to help design this AI chip. So in theory if Google needs more AI chips then they're going to help and make more chips with Broadcom, right? The design process Broadcom gets a form of the fee and these chips are made in TSMC. So Broadcom is definitely going to be a winner. And I think after hours that's why the stock is up about 0.5% because the excitement is coming from this news. Now the question is is Nvidia a loser in this race and again on a top level overview it's easy to see why a lot of fint twitterers a lot of fake Nvidia and AI shareholder knowowers are going to say yes. But from what we know in this market what do we know? First thing we know, this is a constraint market where there's not enough chips to go around and I don't think that's going to change anytime soon. The second thing is more people are going to continue to sign up for OpenAI's platforms, not less people. So you need open AI is seeing a huge growth from their training needs but also from the demand of all the solutions that are being used by people and on a every weekly basis monthly basis more people become familiar with open AAI are familiar with Gemini with Grock. So the need for chips are going to continue to grow at rapid levels. I think for the foreseeable future we're still going to be chip constrainted and that is not going to stop no matter what Google or Amazon or OpenAI uses as a overall chip company. The other thing is OpenAI and this is what I think is happening. OpenAI has a lot of solutions. They have a lot of different models. They have video models. They have audio models. They have large language models for inference. one shot oneot as well models that don't really do any form of uh thinking. There might be some models that OpenAI would rather push into Google's TPU and then that opens up their Nvidia chips so they can continue to innovate with those models instead. So maybe the weaker models or the models that don't need to be updated very quickly or the workloads aren't shifting, it makes the most sense to kind of offset that to something a little bit cheaper like the TPU, but they still need those other solutions to continue to grow and continue to innovate. So as an Nvidia shareholder, this is nothing I would be worried about. this market is growing so quickly and I'll take a closer look at some charts in a bit that OpenAI needs to continue to get more and more and more capacity. So that to me is extremely bullish. Now if we look at a recent keynote that Jensen the CEO of Nvidia was he actually talks about the ASIC market. He mentions look a lot of AS6 are started most of them are cancelled and the reason for that is that what's the point of building an ASIC if it's not going to be better than the one you can buy in some very specific measure and we're moving so fast and the bar that we are we're raising is so so incredible it's not easy it really isn't easy to build you know so you know Jensen has been doing this for 30 years and it seems harder than ever and then somebody goes yeah I'll do an ASIC And so I'm delighted to hear everybody is interested in building AS6, but he does believe most of them are going to get cancelled. So in this AI race that is moving so quickly, it's not only if you have your own AI chip. There is only X amount of power that you can use because we are power constrained. Are you really going to use a chip that's much weaker than the most updated version? Because your competitor is going to use the most updated version. They're going to use the Black or the Vera Rupin or whatever. And if you're using some ASIC solution just to save a few extra dollars on the building, but you're going to lose on revenue potential, it makes no sense. So Nvidia, as long as they keep to innovate, as long they keep innovating at a yearly cadence, I don't think there's anything to worry about because this market is ever ever evolving. A perfect example is Microsoft. There are reports that Microsoft's nextg AI chip production delayed to 2026. What is the point of making a chip that's going to come out in 2026 that you are creating specs of being competiting to a chip that Nvidia made in 2024 or 2025? Nvidia in 2026 is going to have already the Blackwell Ultra. It's going to be getting ramp ready to ramp up the Vera Rubin. If you're building a chip and you're limited in how much data center space you have, building a chip that is two, three generations behind is the dumbest move you can make. So for me, as long as this AI market continues to innovate, it is still extremely much an Nvidia market and no news like this is going to be scary. Again, Open AI, this to me is not an indication that OpenAI is trying to escape Nvidia's presence. This to me is news that OpenAI has no choice with how much demand they're seeing in the AI solution that they're trying to work with whoever can give them any chips. Again, we saw the Stargate project, we saw the coreweave project, we saw the kind of reports that they are out of GPUs almost on the monthly basis. They continue to see massive demand growth. Now, what else did I want to show you? So, outside of that, this AI infrastructure market and now we're back in fiscal.ai, uh, Marll Technologies, which is another semiconductor company, recently had an AI event. And I think this slideshow explains a lot. So when we think of AI spending, usually we just think of four players. Meta, Google, Microsoft, and Amazon. That should no longer be the case because now you have other companies spending a lot and lots of money. Google's not the only one, right? It's not the 25%. You have companies like XAI, OpenAI, Stargate, you have Apple, you have Tesla, you have the list goes on as a lot of other individual companies are spending billions of dollars on the yearly basis for these chips. So for me to think that Nvidia is going to lose any forms of revenue, it's going to have any form of adwin because of this, I think at this moment is fool's stinking if you understand the industry. Yeah, I could 100% understand if you don't follow this company, if you don't follow this market where the first thought that goes is this is bad news for Nvidia. I'm not going to fault you for it. But again, you come to this channel because you want to learn about the AI space. You want to learn what's really happening and you don't want to follow the overall the people that you think know what's happening. Uh so I I think Broadcom can definitely benefit. I think Nvidia is nothing to worry about, but the market might actually perceive this as a whole different case. I think in the next week when the market opens up, you might see this as being one of the big news and kind of creating some negative pressure for the stock. I don't really expect much of a sell-off, but if it is, make sure to stay tuned to this channels. We'll talk about that as well. Now, I think that's all that I have. If you have any questions, feel free to let me know in the comments below. If you have any thoughts of why I could be wrong, let me know in the comments below. But again, it's Friday night. It's most likely Saturday morning. You have yet anything to do, make sure to hit the thumbs up and the subscribe button. Peace out.\n"
     ]
    }
   ],
   "source": [
    "# Combine all caption text\n",
    "text = \" \".join([entry['text'] for entry in transcript])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is one of the most profound and debated questions in philosophy, spirituality, and science. The answer depends on personal beliefs, perspectives, and experiences. Here are a few common viewpoints:\n",
      "\n",
      "1. **Philosophical Perspectives**:\n",
      "   - **Existentialism (e.g., Sartre, Camus)**: Life has no inherent meaning—we must create our own purpose through choices and actions.\n",
      "   - **Absurdism (Albert Camus)**: Life may lack inherent meaning, but we can find joy in resisting despair and embracing the absurdity.\n",
      "   - **Stoicism**: Meaning comes from virtue, rationality, and acceptance of what we cannot control.\n",
      "\n",
      "2. **Religious/Spiritual Views**:\n",
      "   - Many religions propose that life’s purpose is tied to divine will, enlightenment, or serving a higher power (e.g., love, justice, or devotion).\n",
      "   - For example, Christianity might say: \"To know, love, and serve God\" (St. Ignatius of Loyola).\n",
      "\n",
      "3. **Scientific Perspectives**:\n",
      "   - Biologists might argue life’s purpose is survival, reproduction, and evolution.\n",
      "   - Cosmologists or physicists might see life as a rare, emergent phenomenon in an indifferent universe.\n",
      "\n",
      "4. **Personal Meaning**:\n",
      "   - Some find purpose in relationships, creativity, helping others, or personal growth.\n",
      "   - Viktor Frankl (Holocaust survivor and psychiatrist) suggested meaning comes from suffering with purpose, love, or contributing to something beyond oneself.\n",
      "\n",
      "Ultimately, the \"meaning of life\" may be a deeply personal answer. Some embrace the journey of discovering it; others focus on lives of joy, connection, or discovery.\n",
      "\n",
      "What resonates with you?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"sk-or-\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is the meaning of life?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
